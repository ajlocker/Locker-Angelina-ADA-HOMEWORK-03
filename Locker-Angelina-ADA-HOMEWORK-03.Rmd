---
title: "Locker-Angelina-ADA-HOMEWORK-03"
author: "Angelina Locker"
date: "March 14, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

PROBLEM 1
z <- pa - pb / sqrt (pq/n1 + pq/n2)

```{r}



z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0 = NULL, conf.level = 0.95, alternative = "two.sided", correct = FALSE) {
  if ((n1 * p1 < 5) & (n1 * (1 - p0)< 5)) {warning("WARNING: Probably not a normal distribution")}
  if (is.null(p2) | is.null(n2)) {
    z <- (p1 - p0)/sqrt(p0 * (1 - p0)/n1)
} 
  else {
    ppop <- (sum(p1) + sum(p2))/(n1+n2)
    z <- (p2-p1-p0)/sqrt((ppop*(1-ppop))*((1/n1)+(1/n2)))
}
    if(alternative=="two.sided") {
    p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
  }
  if(alternative=="greater") {
    p <- 1 - pnorm(z, lower.tail = TRUE)
  }
  if(alternative=="less") {
    p <- pnorm(z, lower.tail = FALSE)
  }
  if(is.null(p2)|is.null(n2)) {
    phat <- mean(p1)
    lower <- phat - qnorm(0.95) * sqrt(phat * (1 - phat)/(n1))
    upper <- phat + qnorm(0.95) * sqrt(phat * (1 - phat)/(n1))
    CI <- c(lower, upper)
  }
  else {
    phat <- (p2 + p1)/(n2+n1)
    lower <- phat - qnorm(0.95) * sqrt(phat * ((1 - phat)/(n1+n2)))
    upper <- phat + qnorm(0.95) * sqrt(phat * ((1 - phat)/(n1+n2)))
    CI <- c(lower, upper)
  }
alpha <- 1 - conf.level
crit <- qnorm(1 - alpha/2)
test <- abs(z) > crit

  return(list("z test" = z, "p value" = p, "Confidence Interval" = CI, "test" = test))
}
```

```{r}
z.prop.test(p1 = 0.8, n1 = 100, p0 = 0.9)
```

```{r}
z.prop.test(p1 = 0.8, n1 = 100, p2 = 0.3, n2 = 407, p0 = 0.9)
```

```{r}
z.prop.test(p1 = 0.8, n1 = 100, p0 = 0.9, alternative = "less")
```

```{r}
z.prop.test(p1 = 0.8, n1 = 100, p0 = 0.9, alternative = "greater")
```

```{r}
z.prop.test(p1 = 0.3, n1 = 4, p0 = 0.2)
```

PROBLEM 2

```{r}
library(tidyverse)
library(readr)
library(ggplot2)
f <- "https://raw.githubusercontent.com/difiore/ADA-2019/master/KamilarAndCooperData.csv"
d <- read_csv(f, col_names = TRUE)
head(d)
```

```{r}
l <- (d$MaxLongevity_m)
bs <- (d$Brain_Size_Species_Mean)

ll <- log(l)
lbs <- log(bs)

l2bs <- lm(data = d, l ~ bs)
l2bs
```

```{r}
g <- ggplot(data=d, aes(x = bs, y= l))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g <- g + ggtitle("Linear Regression Longevity to Brain Size")
g <- g + xlab("Brain Size")
g <- g + ylab("Longevity")
g <- g + geom_abline(intercept = 248.952, slope = 1.218, size = 1, colour = "blue", 
        alpha = 1/2)
g <- g + geom_text(x=250, y=250,  label="y=1.218x + 248.952", color="red")
g
```

```{r}
B1lbs <- 1.218
#Null hypothesis is rejected

```

Using your model, add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.

```{r}
ci <- predict(l2bs, newdata = data.frame(Size = d$Brain_Size_Species_Mean), interval = "confidence", level = 0.90)  
head(ci)
```

```{r}
pi <- predict(l2bs, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)  
head(pi)
```

```{r}
l2bs <- lm(data = d, l ~ bs)
L_hat <- predict(l2bs, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean))
df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, L_hat, ci, pi))
names(df) <- c("x", "y", "Lhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)
```

```{r}
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 0.5)

g <- g + geom_line(aes(x = x, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = x, y = CIlwr), colour = "red")
g <- g + geom_line(aes(x = x, y = CIupr), colour = "red")
g <- g + geom_line(aes(x = x, y = PIfit), colour = "black")
g <- g + geom_line(aes(x = x, y = PIlwr), colour = "blue")
g <- g + geom_line(aes(x = x, y = PIupr), colour = "blue")
g <- g + scale_color_identity(name = "Model fit",
                          breaks = c("black", "red", "blue"),
                          labels = c("CI and PI Fit", "90% confidence intervals", "90% prediction intervals"),
                          guide = "legend")
g


```


```{r}
logl2bs <- lm(data = d, ll ~ lbs)
logl2bs


```

```{r}
g2 <- ggplot(data=d, aes(x = lbs, y= ll))
g2 <- g2 + geom_point()
g2 <- g2 + geom_smooth(method = "lm", formula = y ~ x)
g2 <- g2 + ggtitle("Linear Regression Log Longevity to Log Brain Size")
g2 <- g2 + xlab("Log Brain Size")
g2 <- g2 + ylab("Log Longevity")
g2 <- g2 + geom_abline(intercept = 4.8790, slope = 0.2341, size = 1, colour = "blue", 
        alpha = 1/2)
g2 <- g2 + geom_text(x=4, y=5,  label="y=0.2341x + 4.8790", color="red")
g2
```

```{r}
B1log <- 0.2341
#Null hypothesis is rejected

ci2 <- predict(logl2bs, newdata = data.frame(Size = d$Brain_Size_Species_Mean), interval = "confidence", level = 0.90)  
head(ci2)

```

```{r}
pi2 <- predict(logl2bs, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)  
head(pi2)
```
Using your model, add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.

```{r}

logl2bs <- lm(data = d, ll ~ lbs)
LL_hat <- predict(logl2bs, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean))
df2 <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, LL_hat, ci2, pi2))
names(df2) <- c("x", "y", "LLHat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df2)


```

```{r}

g2 <- ggplot(data = df2, aes(x = x, y = y))
g2 <- g2 + geom_point(alpha = 0.1)
g2 <- g2 + geom_line(aes(x = x, y = CIfit), colour = "black")
g2 <- g2 + geom_line(aes(x = x, y = CIlwr), colour = "red")
g2 <- g2 + geom_line(aes(x = x, y = CIupr), colour = "red")
g2 <- g2 + geom_line(aes(x = x, y = PIfit), colour = "black")
g2 <- g2 + geom_line(aes(x = x, y = PIlwr), colour = "blue")
g2 <- g2 + geom_line(aes(x = x, y = PIupr), colour = "blue")
g2 <- g2 + scale_color_identity(name=" ", breaks=c("black", "red", "blue"), labels=c("CI Fit", "90% confidence intervals", "90% prediction intervals"), guide="legend")
g2

```


Produce a point estimate and associated 90% prediction interval for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
```{r}
pi800 <- predict(l2bs, newdata = data.frame(x = 800), interval = "prediction", 
    level = 0.90)  
pi

# I wouldn't really trust this prediction since 800 is way beyond the collected data. 
```


Looking at your two models, which do you think is better? Why?
#I think the first model looks better, since the data actually falls within the projected confidence and prediction intervals; however, I may have just messed up my second model? 



